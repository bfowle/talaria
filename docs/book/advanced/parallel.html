<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Parallel Processing - Talaria Documentation</title>


        <!-- Custom HTML head -->
        <!-- MathJax Configuration -->
        <script>
        window.MathJax = {
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true
          },
          TeX: {
            equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"]
          }
        };
        </script>
        <meta name="description" content="Intelligent FASTA reduction for aligner index optimization">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "ayu";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Talaria Documentation</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Andromeda-Tech/talaria" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/Andromeda-Tech/talaria/edit/main/docs/src/advanced/parallel.md" title="Suggest an edit" aria-label="Suggest an edit" rel="edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h1>
<p>Advanced parallel and concurrent processing strategies for maximizing throughput on multi-core systems.</p>
<h2 id="parallelization-architecture"><a class="header" href="#parallelization-architecture">Parallelization Architecture</a></h2>
<h3 id="threading-model"><a class="header" href="#threading-model">Threading Model</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use rayon::prelude::*;
use std::sync::Arc;
use crossbeam::channel;

pub struct ParallelProcessor {
    thread_pool: rayon::ThreadPool,
    chunk_size: usize,
    work_stealing: bool,
}

impl ParallelProcessor {
    pub fn new(num_threads: usize) -&gt; Result&lt;Self&gt; {
        let thread_pool = rayon::ThreadPoolBuilder::new()
            .num_threads(num_threads)
            .thread_name(|idx| format!("talaria-worker-{}", idx))
            .build()?;
        
        Ok(Self {
            thread_pool,
            chunk_size: 1000,
            work_stealing: true,
        })
    }
    
    pub fn process_parallel&lt;T&gt;(&amp;self, items: Vec&lt;T&gt;) -&gt; Vec&lt;Result&lt;T&gt;&gt;
    where
        T: Send + Sync + 'static,
    {
        self.thread_pool.install(|| {
            items.into_par_iter()
                .chunks(self.chunk_size)
                .flat_map(|chunk| {
                    chunk.into_iter()
                        .map(|item| self.process_item(item))
                        .collect::&lt;Vec&lt;_&gt;&gt;()
                })
                .collect()
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="work-distribution"><a class="header" href="#work-distribution">Work Distribution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use dashmap::DashMap;
use parking_lot::RwLock;

pub struct WorkDistributor {
    tasks: Arc&lt;RwLock&lt;VecDeque&lt;Task&gt;&gt;&gt;,
    results: Arc&lt;DashMap&lt;usize, Result&gt;&gt;,
    workers: Vec&lt;JoinHandle&lt;()&gt;&gt;,
}

impl WorkDistributor {
    pub fn distribute(&amp;self, num_workers: usize) {
        let (tx, rx) = crossbeam::channel::bounded(num_workers * 2);
        
        // Producer thread
        let producer = thread::spawn(move || {
            while let Some(task) = self.get_next_task() {
                tx.send(task).unwrap();
            }
        });
        
        // Worker threads
        for _ in 0..num_workers {
            let rx = rx.clone();
            let results = Arc::clone(&amp;self.results);
            
            let worker = thread::spawn(move || {
                while let Ok(task) = rx.recv() {
                    let result = process_task(task);
                    results.insert(task.id, result);
                }
            });
            
            self.workers.push(worker);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="data-parallelism"><a class="header" href="#data-parallelism">Data Parallelism</a></h2>
<h3 id="parallel-iteration"><a class="header" href="#parallel-iteration">Parallel Iteration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use rayon::prelude::*;

pub fn parallel_reduction(sequences: &amp;[Sequence]) -&gt; Vec&lt;Reference&gt; {
    sequences.par_iter()
        .chunks(1000)
        .map(|chunk| {
            // Process chunk in parallel
            chunk.par_iter()
                .filter(|seq| seq.length() &gt; MIN_LENGTH)
                .map(|seq| compute_similarity(seq))
                .collect::&lt;Vec&lt;_&gt;&gt;()
        })
        .flatten()
        .collect()
}

pub fn parallel_alignment(queries: &amp;[Sequence], references: &amp;[Sequence]) -&gt; Vec&lt;Alignment&gt; {
    queries.par_iter()
        .flat_map(|query| {
            references.par_iter()
                .map(|reference| align(query, reference))
                .collect::&lt;Vec&lt;_&gt;&gt;()
        })
        .collect()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="simd-parallelism"><a class="header" href="#simd-parallelism">SIMD Parallelism</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use packed_simd::{u8x32, f32x8};

pub fn simd_sequence_comparison(seq1: &amp;[u8], seq2: &amp;[u8]) -&gt; u32 {
    let mut matches = 0u32;
    let chunks = seq1.chunks_exact(32).zip(seq2.chunks_exact(32));
    
    for (chunk1, chunk2) in chunks {
        let v1 = u8x32::from_slice_unaligned(chunk1);
        let v2 = u8x32::from_slice_unaligned(chunk2);
        let mask = v1.eq(v2);
        matches += mask.select(u8x32::splat(1), u8x32::splat(0)).wrapping_sum() as u32;
    }
    
    // Handle remainder
    let remainder1 = &amp;seq1[seq1.len() &amp; !31..];
    let remainder2 = &amp;seq2[seq2.len() &amp; !31..];
    matches += remainder1.iter()
        .zip(remainder2.iter())
        .filter(|(a, b)| a == b)
        .count() as u32;
    
    matches
}
<span class="boring">}</span></code></pre></pre>
<h2 id="task-parallelism"><a class="header" href="#task-parallelism">Task Parallelism</a></h2>
<h3 id="pipeline-architecture"><a class="header" href="#pipeline-architecture">Pipeline Architecture</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::mpsc;
use futures::stream::{Stream, StreamExt};

pub struct Pipeline {
    stages: Vec&lt;Box&lt;dyn Stage&gt;&gt;,
}

#[async_trait]
trait Stage: Send + Sync {
    async fn process(&amp;self, input: Data) -&gt; Result&lt;Data&gt;;
}

impl Pipeline {
    pub async fn run(&amp;self, input: impl Stream&lt;Item = Data&gt;) -&gt; impl Stream&lt;Item = Result&lt;Data&gt;&gt; {
        let (tx, mut rx) = mpsc::channel(100);
        
        // Chain stages
        let mut stream = Box::pin(input);
        for stage in &amp;self.stages {
            stream = Box::pin(stream.then(move |data| async move {
                stage.process(data).await
            }));
        }
        
        // Collect results
        tokio::spawn(async move {
            while let Some(result) = stream.next().await {
                let _ = tx.send(result).await;
            }
        });
        
        rx
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="concurrent-io"><a class="header" href="#concurrent-io">Concurrent I/O</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::fs::File;
use tokio::io::{AsyncBufReadExt, AsyncWriteExt};

pub async fn concurrent_file_processing(paths: Vec&lt;PathBuf&gt;) -&gt; Result&lt;()&gt; {
    let semaphore = Arc::new(Semaphore::new(10)); // Limit concurrent files
    
    let tasks = paths.into_iter().map(|path| {
        let sem = Arc::clone(&amp;semaphore);
        
        tokio::spawn(async move {
            let _permit = sem.acquire().await?;
            process_file(path).await
        })
    });
    
    // Wait for all tasks
    let results = futures::future::join_all(tasks).await;
    
    for result in results {
        result??;
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="thread-pools"><a class="header" href="#thread-pools">Thread Pools</a></h2>
<h3 id="custom-thread-pool"><a class="header" href="#custom-thread-pool">Custom Thread Pool</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

pub struct ThreadPool {
    workers: Vec&lt;Worker&gt;,
    sender: mpsc::Sender&lt;Job&gt;,
}

impl ThreadPool {
    pub fn new(size: usize, affinity: Option&lt;Vec&lt;usize&gt;&gt;) -&gt; Self {
        let (sender, receiver) = mpsc::channel();
        let receiver = Arc::new(Mutex::new(receiver));
        
        let workers = (0..size)
            .map(|id| {
                let receiver = Arc::clone(&amp;receiver);
                Worker::new(id, receiver, affinity.as_ref().map(|a| a[id]))
            })
            .collect();
        
        ThreadPool { workers, sender }
    }
    
    pub fn execute&lt;F&gt;(&amp;self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);
        self.sender.send(job).unwrap();
    }
}

struct Worker {
    id: usize,
    thread: Option&lt;thread::JoinHandle&lt;()&gt;&gt;,
}

impl Worker {
    fn new(id: usize, receiver: Arc&lt;Mutex&lt;mpsc::Receiver&lt;Job&gt;&gt;&gt;, cpu: Option&lt;usize&gt;) -&gt; Worker {
        let thread = thread::spawn(move || {
            // Set CPU affinity if specified
            if let Some(cpu) = cpu {
                set_cpu_affinity(cpu);
            }
            
            loop {
                let job = receiver.lock().unwrap().recv();
                
                match job {
                    Ok(job) =&gt; job(),
                    Err(_) =&gt; break,
                }
            }
        });
        
        Worker {
            id,
            thread: Some(thread),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="work-stealing"><a class="header" href="#work-stealing">Work Stealing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crossbeam::deque::{Injector, Stealer, Worker};

pub struct WorkStealingPool {
    global: Arc&lt;Injector&lt;Task&gt;&gt;,
    workers: Vec&lt;WorkerThread&gt;,
}

struct WorkerThread {
    local: Worker&lt;Task&gt;,
    stealers: Vec&lt;Stealer&lt;Task&gt;&gt;,
    global: Arc&lt;Injector&lt;Task&gt;&gt;,
}

impl WorkerThread {
    fn run(&amp;mut self) {
        loop {
            // Try local queue first
            if let Some(task) = self.local.pop() {
                process_task(task);
                continue;
            }
            
            // Try stealing from others
            for stealer in &amp;self.stealers {
                if let Some(task) = stealer.steal().success() {
                    process_task(task);
                    continue;
                }
            }
            
            // Try global queue
            if let Some(task) = self.global.steal().success() {
                process_task(task);
                continue;
            }
            
            // No work available, yield
            thread::yield_now();
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="synchronization"><a class="header" href="#synchronization">Synchronization</a></h2>
<h3 id="lock-free-data-structures"><a class="header" href="#lock-free-data-structures">Lock-Free Data Structures</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crossbeam::queue::ArrayQueue;
use atomic::{Atomic, Ordering};

pub struct LockFreeCache&lt;T&gt; {
    queue: ArrayQueue&lt;T&gt;,
    size: Atomic&lt;usize&gt;,
}

impl&lt;T&gt; LockFreeCache&lt;T&gt; {
    pub fn new(capacity: usize) -&gt; Self {
        Self {
            queue: ArrayQueue::new(capacity),
            size: Atomic::new(0),
        }
    }
    
    pub fn insert(&amp;self, item: T) -&gt; bool {
        if self.queue.push(item).is_ok() {
            self.size.fetch_add(1, Ordering::SeqCst);
            true
        } else {
            false
        }
    }
    
    pub fn get(&amp;self) -&gt; Option&lt;T&gt; {
        self.queue.pop().map(|item| {
            self.size.fetch_sub(1, Ordering::SeqCst);
            item
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-reduction"><a class="header" href="#parallel-reduction">Parallel Reduction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::atomic::{AtomicU64, Ordering};

pub struct ParallelAccumulator {
    partials: Vec&lt;AtomicU64&gt;,
    num_threads: usize,
}

impl ParallelAccumulator {
    pub fn new(num_threads: usize) -&gt; Self {
        let partials = (0..num_threads)
            .map(|_| AtomicU64::new(0))
            .collect();
        
        Self {
            partials,
            num_threads,
        }
    }
    
    pub fn add(&amp;self, thread_id: usize, value: u64) {
        self.partials[thread_id].fetch_add(value, Ordering::Relaxed);
    }
    
    pub fn sum(&amp;self) -&gt; u64 {
        self.partials.iter()
            .map(|partial| partial.load(Ordering::Relaxed))
            .sum()
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="gpu-acceleration"><a class="header" href="#gpu-acceleration">GPU Acceleration</a></h2>
<h3 id="cuda-integration"><a class="header" href="#cuda-integration">CUDA Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use cuda_sys::*;

pub struct CudaAligner {
    device: i32,
    context: CUcontext,
    module: CUmodule,
}

impl CudaAligner {
    pub fn new(device_id: i32) -&gt; Result&lt;Self&gt; {
        unsafe {
            cuInit(0);
            
            let mut device = 0;
            cuDeviceGet(&amp;mut device, device_id);
            
            let mut context = std::ptr::null_mut();
            cuCtxCreate_v2(&amp;mut context, 0, device);
            
            let mut module = std::ptr::null_mut();
            let ptx = include_str!("../kernels/alignment.ptx");
            cuModuleLoadData(&amp;mut module, ptx.as_ptr() as *const _);
            
            Ok(Self {
                device: device_id,
                context,
                module,
            })
        }
    }
    
    pub fn align_batch(&amp;self, sequences: &amp;[Sequence]) -&gt; Vec&lt;Alignment&gt; {
        // Transfer data to GPU
        let d_sequences = self.upload_sequences(sequences);
        
        // Launch kernel
        let block_size = 256;
        let grid_size = (sequences.len() + block_size - 1) / block_size;
        
        unsafe {
            let mut kernel = std::ptr::null_mut();
            cuModuleGetFunction(&amp;mut kernel, self.module, b"align_kernel\0".as_ptr() as *const _);
            
            cuLaunchKernel(
                kernel,
                grid_size as u32, 1, 1,
                block_size as u32, 1, 1,
                0,
                std::ptr::null_mut(),
                &amp;d_sequences as *const _ as *mut _,
                std::ptr::null_mut(),
            );
        }
        
        // Get results
        self.download_alignments(d_sequences)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="opencl-support"><a class="header" href="#opencl-support">OpenCL Support</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use ocl::{ProQue, Buffer, Program};

pub struct OpenCLProcessor {
    pro_que: ProQue,
}

impl OpenCLProcessor {
    pub fn new() -&gt; Result&lt;Self&gt; {
        let src = include_str!("../kernels/reduction.cl");
        
        let pro_que = ProQue::builder()
            .src(src)
            .dims(1024)
            .build()?;
        
        Ok(Self { pro_que })
    }
    
    pub fn process_batch(&amp;self, data: &amp;[f32]) -&gt; Result&lt;Vec&lt;f32&gt;&gt; {
        let buffer = Buffer::builder()
            .queue(self.pro_que.queue().clone())
            .flags(ocl::flags::MEM_READ_WRITE)
            .len(data.len())
            .copy_host_slice(data)
            .build()?;
        
        let kernel = self.pro_que.kernel_builder("reduce")
            .arg(&amp;buffer)
            .arg(data.len() as u32)
            .build()?;
        
        unsafe { kernel.enq()? }
        
        let mut result = vec![0.0f32; data.len()];
        buffer.read(&amp;mut result).enq()?;
        
        Ok(result)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="thread-pool-configuration"><a class="header" href="#thread-pool-configuration">Thread Pool Configuration</a></h3>
<pre><code class="language-toml">[parallel.threadpool]
# Thread pool settings
num_threads = 0           # 0 = auto-detect
stack_size_mb = 8        # Stack size per thread
work_stealing = true      # Enable work stealing
yield_strategy = "spin"  # Options: spin, yield, park

# CPU affinity
pin_threads = true
affinity_mode = "compact" # Options: compact, scatter, numa
</code></pre>
<h3 id="parallel-algorithm-settings"><a class="header" href="#parallel-algorithm-settings">Parallel Algorithm Settings</a></h3>
<pre><code class="language-toml">[parallel.algorithms]
# Chunk sizes for parallel processing
chunk_size = 1000
dynamic_chunking = true
min_chunk_size = 100
max_chunk_size = 10000

# Load balancing
load_balancing = "dynamic" # Options: static, dynamic, guided
steal_threshold = 0.5       # Work stealing threshold
</code></pre>
<h3 id="gpu-configuration"><a class="header" href="#gpu-configuration">GPU Configuration</a></h3>
<pre><code class="language-toml">[parallel.gpu]
# GPU settings
use_gpu = false
gpu_device = 0
gpu_memory_gb = 8
batch_size = 1024

# CUDA settings
cuda_threads_per_block = 256
cuda_shared_memory_kb = 48
cuda_streams = 4

# OpenCL settings
opencl_platform = 0
opencl_work_group_size = 256
</code></pre>
<h2 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h2>
<h3 id="thread-contention"><a class="header" href="#thread-contention">Thread Contention</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use parking_lot::{RwLock, Mutex};
use std::sync::atomic::{AtomicBool, Ordering};

pub struct ContentionReducer {
    // Use RwLock for read-heavy workloads
    read_heavy: RwLock&lt;HashMap&lt;String, Vec&lt;u8&gt;&gt;&gt;,
    
    // Use sharded locks for write-heavy workloads
    write_heavy: Vec&lt;Mutex&lt;HashMap&lt;String, Vec&lt;u8&gt;&gt;&gt;&gt;,
    
    // Use atomics for simple flags
    flag: AtomicBool,
}

impl ContentionReducer {
    pub fn read_optimized(&amp;self, key: &amp;str) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {
        self.read_heavy.read().get(key).cloned()
    }
    
    pub fn write_optimized(&amp;self, key: String, value: Vec&lt;u8&gt;) {
        let shard = hash(&amp;key) % self.write_heavy.len();
        self.write_heavy[shard].lock().insert(key, value);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="false-sharing"><a class="header" href="#false-sharing">False Sharing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::atomic::{AtomicUsize, Ordering};

// Avoid false sharing with padding
#[repr(C, align(64))] // Cache line size
pub struct PaddedCounter {
    count: AtomicUsize,
    _padding: [u8; 56], // 64 - 8 = 56 bytes padding
}

pub struct CounterArray {
    counters: Vec&lt;PaddedCounter&gt;,
}

impl CounterArray {
    pub fn increment(&amp;self, thread_id: usize) {
        self.counters[thread_id].count.fetch_add(1, Ordering::Relaxed);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="debugging-parallel-code"><a class="header" href="#debugging-parallel-code">Debugging Parallel Code</a></h2>
<h3 id="race-condition-detection"><a class="header" href="#race-condition-detection">Race Condition Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(debug_assertions)]
pub struct DebugLock&lt;T&gt; {
    data: Mutex&lt;T&gt;,
    owner: AtomicUsize,
    access_log: Mutex&lt;Vec&lt;AccessRecord&gt;&gt;,
}

#[cfg(debug_assertions)]
impl&lt;T&gt; DebugLock&lt;T&gt; {
    pub fn lock(&amp;self) -&gt; MutexGuard&lt;T&gt; {
        let thread_id = thread::current().id();
        
        // Log access attempt
        self.access_log.lock().unwrap().push(AccessRecord {
            thread_id,
            timestamp: Instant::now(),
            operation: "lock",
        });
        
        let guard = self.data.lock().unwrap();
        self.owner.store(thread_id.as_u64(), Ordering::SeqCst);
        
        guard
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="deadlock-detection"><a class="header" href="#deadlock-detection">Deadlock Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::{Arc, Mutex};
use std::collections::HashMap;

pub struct DeadlockDetector {
    graph: Arc&lt;Mutex&lt;HashMap&lt;ThreadId, Vec&lt;ThreadId&gt;&gt;&gt;&gt;,
}

impl DeadlockDetector {
    pub fn check_deadlock(&amp;self) -&gt; bool {
        let graph = self.graph.lock().unwrap();
        
        // Perform cycle detection in wait-for graph
        for start in graph.keys() {
            if self.has_cycle(&amp;graph, start, &amp;mut HashSet::new()) {
                return true;
            }
        }
        
        false
    }
    
    fn has_cycle(&amp;self, graph: &amp;HashMap&lt;ThreadId, Vec&lt;ThreadId&gt;&gt;, 
                 node: &amp;ThreadId, visited: &amp;mut HashSet&lt;ThreadId&gt;) -&gt; bool {
        if visited.contains(node) {
            return true;
        }
        
        visited.insert(*node);
        
        if let Some(neighbors) = graph.get(node) {
            for neighbor in neighbors {
                if self.has_cycle(graph, neighbor, visited) {
                    return true;
                }
            }
        }
        
        visited.remove(node);
        false
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="benchmarking-parallel-code"><a class="header" href="#benchmarking-parallel-code">Benchmarking Parallel Code</a></h2>
<h3 id="scalability-testing"><a class="header" href="#scalability-testing">Scalability Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, Criterion, BenchmarkId};

fn parallel_scaling_benchmark(c: &amp;mut Criterion) {
    let mut group = c.benchmark_group("parallel_scaling");
    
    for num_threads in [1, 2, 4, 8, 16, 32] {
        group.bench_with_input(
            BenchmarkId::from_parameter(num_threads),
            &amp;num_threads,
            |b, &amp;num_threads| {
                let pool = rayon::ThreadPoolBuilder::new()
                    .num_threads(num_threads)
                    .build()
                    .unwrap();
                
                b.iter(|| {
                    pool.install(|| {
                        black_box(parallel_workload())
                    })
                });
            },
        );
    }
    
    group.finish();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="contention-analysis"><a class="header" href="#contention-analysis">Contention Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ContentionMonitor {
    lock_acquisitions: AtomicU64,
    lock_contentions: AtomicU64,
    wait_time_ns: AtomicU64,
}

impl ContentionMonitor {
    pub fn measure_contention&lt;T, F&gt;(&amp;self, f: F) -&gt; T
    where
        F: FnOnce() -&gt; T,
    {
        let start = Instant::now();
        self.lock_acquisitions.fetch_add(1, Ordering::Relaxed);
        
        let result = f();
        
        let wait_time = start.elapsed().as_nanos() as u64;
        if wait_time &gt; 1000 { // More than 1 microsecond
            self.lock_contentions.fetch_add(1, Ordering::Relaxed);
        }
        self.wait_time_ns.fetch_add(wait_time, Ordering::Relaxed);
        
        result
    }
    
    pub fn report(&amp;self) -&gt; ContentionReport {
        ContentionReport {
            total_acquisitions: self.lock_acquisitions.load(Ordering::Relaxed),
            contentions: self.lock_contentions.load(Ordering::Relaxed),
            avg_wait_ns: self.wait_time_ns.load(Ordering::Relaxed) / 
                        self.lock_acquisitions.load(Ordering::Relaxed),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Minimize Shared State</strong>: Reduce contention</li>
<li><strong>Use Appropriate Granularity</strong>: Balance overhead vs parallelism</li>
<li><strong>Avoid False Sharing</strong>: Align to cache lines</li>
<li><strong>Profile First</strong>: Measure before optimizing</li>
<li><strong>Consider NUMA</strong>: Optimize for memory locality</li>
<li><strong>Handle Errors</strong>: Graceful degradation in parallel code</li>
<li><strong>Test Thoroughly</strong>: Race conditions are hard to reproduce</li>
<li><strong>Document Assumptions</strong>: Thread safety requirements</li>
</ol>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="performance.html">Performance Optimization</a> - General performance tuning</li>
<li><a href="memory.html">Memory Management</a> - Memory considerations for parallel code</li>
<li><a href="../user-guide/configuration.html">Configuration</a> - Parallel processing settings</li>
<li><a href="../benchmarks/performance.html">Benchmarks</a> - Parallel performance metrics</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../advanced/performance.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../advanced/memory.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../advanced/performance.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../advanced/memory.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
